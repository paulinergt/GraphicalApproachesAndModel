{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a448684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de 6/8 coeurs CPU\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import validate_data, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Configuration parall√©lisation Apple Silicon (80% des coeurs)\n",
    "n_cores_total = mp.cpu_count()\n",
    "n_cores_use = max(1, int(0.8 * n_cores_total))\n",
    "print(f\"Utilisation de {n_cores_use}/{n_cores_total} coeurs CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "434a91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 : impl√©mentation d'un classifieur Bay√©sien avec apprentissage de structure\n",
    "\n",
    "class BayesianClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = validate_data(self, X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        if self.model is None and PGMPY_AVAILABLE:\n",
    "            # Convertir en DataFrame et discr√©tiser\n",
    "            if not hasattr(X, 'columns'):\n",
    "                X = pd.DataFrame(X, columns=[f'f_{i}' for i in range(X.shape[1])])\n",
    "            \n",
    "            # Prendre seulement 5 features pour simplifier\n",
    "            X_small = X.iloc[:, :5]\n",
    "            \n",
    "            # Discr√©tisation simple en 3 bins\n",
    "            for col in X_small.columns:\n",
    "                if X_small[col].dtype in ['float64', 'int64']:\n",
    "                    X_small[col] = pd.cut(X_small[col], bins=3, labels=['low', 'mid', 'high'])\n",
    "            \n",
    "            # Ajouter la cible\n",
    "            data = pd.concat([X_small, pd.Series(y, name='target')], axis=1)\n",
    "            \n",
    "            # Apprentissage de structure Hill Climbing\n",
    "            hc = HillClimbSearch(data)\n",
    "            model_structure = hc.estimate(max_iter=50)\n",
    "            \n",
    "            # Cr√©er le r√©seau bay√©sien\n",
    "            self.model = DiscreteBayesianNetwork(model_structure.edges())\n",
    "            estimator = BayesianEstimator(self.model, data)\n",
    "            for node in self.model.nodes():\n",
    "                self.model.add_cpds(estimator.estimate_cpd(node))\n",
    "            \n",
    "            self.inference_ = VariableElimination(self.model)\n",
    "            self.learned_structure_ = True\n",
    "            self.feature_names_ = X_small.columns.tolist()\n",
    "            \n",
    "        else:\n",
    "            # Fallback GaussianNB\n",
    "            self.model = GaussianNB() if self.model is None else self.model\n",
    "            self.model.fit(X, y)\n",
    "            self.learned_structure_ = False\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        if hasattr(self, 'learned_structure_') and self.learned_structure_:\n",
    "            # Utiliser seulement les 5 premi√®res features\n",
    "            X_small = X.iloc[:, :5] if hasattr(X, 'columns') else X[:, :5]\n",
    "            X_small = pd.DataFrame(X_small, columns=self.feature_names_)\n",
    "            \n",
    "            # Discr√©tiser\n",
    "            for col in X_small.columns:\n",
    "                if X_small[col].dtype in ['float64', 'int64']:\n",
    "                    X_small[col] = pd.cut(X_small[col], bins=3, labels=['low', 'mid', 'high'])\n",
    "            \n",
    "            probabilities = []\n",
    "            for i in range(len(X_small)):\n",
    "                evidence = {col: str(X_small.iloc[i][col]) for col in X_small.columns}\n",
    "                try:\n",
    "                    result = self.inference_.query(['target'], evidence=evidence)\n",
    "                    probabilities.append(result.values)\n",
    "                except:\n",
    "                    probabilities.append([0.5, 0.5])  # Uniforme si erreur\n",
    "            \n",
    "            return np.array(probabilities)\n",
    "        else:\n",
    "            return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "585b8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D√©marrage de l'entra√Ænement du BayesianClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Apprentissage de structure:  30%|‚ñà‚ñà‚ñà       |  30%INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e526141e1c410088efc0ea4d04944a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'f_0': 'O', 'f_1': 'O', 'f_2': 'O', 'f_3': 'O', 'f_4': 'O', 'target': 'C'}\n",
      "‚úÖ Entra√Ænement termin√©: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100%      \n",
      "‚úÖ Entra√Ænement termin√©: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100%      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è  Temps d'entra√Ænement: 0.13s\n",
      "\n",
      " Pr√©dictions en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pr√©diction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è  Temps de pr√©diction: 0.03s\n",
      "\n",
      " R√©sultats:\n",
      " Accuracy: 0.7550\n",
      "\n",
      " Rapport de classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      1.00      0.86       151\n",
      "           Y       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.38      0.50      0.43       200\n",
      "weighted avg       0.57      0.76      0.65       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 2 : application du classifieur Bay√©sien au dataset \n",
    "\n",
    "# Wrapper pour LabelEncoder compatible avec Pipeline et valeurs inconnues\n",
    "class MultiLabelEncoder(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Convertir en DataFrame si n√©cessaire\n",
    "        if not hasattr(X, 'columns'):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        for i, col in enumerate(X.columns):\n",
    "            le = LabelEncoder()\n",
    "            # Ajouter une cat√©gorie sp√©ciale pour les valeurs inconnues\n",
    "            unique_values = list(X.iloc[:, i].astype(str).unique()) + ['__UNKNOWN__']\n",
    "            le.fit(unique_values)\n",
    "            self.label_encoders[i] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convertir en DataFrame si n√©cessaire\n",
    "        if not hasattr(X, 'columns'):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        X_encoded = X.copy()\n",
    "        for i, col in enumerate(X.columns):\n",
    "            if i in self.label_encoders:\n",
    "                # Remplacer les valeurs inconnues par '__UNKNOWN__'\n",
    "                values = X.iloc[:, i].astype(str)\n",
    "                known_values = set(self.label_encoders[i].classes_)\n",
    "                values_safe = [v if v in known_values else '__UNKNOWN__' for v in values]\n",
    "                X_encoded.iloc[:, i] = self.label_encoders[i].transform(values_safe)\n",
    "        \n",
    "        # Retourner en array numpy pour compatibilit√© pipeline\n",
    "        return X_encoded.values\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv('insurance_claims.csv')\n",
    "\n",
    "# D√©finir la cible\n",
    "target = 'fraud_reported' if 'fraud_reported' in df.columns else df.columns[-1]\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Identifier les colonnes num√©riques et cat√©gorielles\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "# Pipeline scikit-learn avec LabelEncoder (√©vite l'explosion combinatoire)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', MultiLabelEncoder())\n",
    "        ]), cat_cols)\n",
    "    ])),\n",
    "    ('classifier', BayesianClassifier())\n",
    "])\n",
    "\n",
    "# Division train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Entra√Ænement et pr√©diction avec barre de progression\n",
    "print(\" D√©marrage de l'entra√Ænement du BayesianClassifier...\")\n",
    "\n",
    "# Barre de progression pour l'entra√Ænement\n",
    "with tqdm(total=100, desc=\"Entra√Ænement\", bar_format='{l_bar}{bar}| {percentage:3.0f}%') as pbar:\n",
    "    pbar.set_description(\"üìö Pr√©paration des donn√©es\")\n",
    "    pbar.update(10)\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    pbar.set_description(\"üîç Apprentissage de structure\")\n",
    "    pbar.update(20)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    pbar.set_description(\"‚úÖ Entra√Ænement termin√©\")\n",
    "    pbar.update(70)\n",
    "\n",
    "print(f\"‚è±Ô∏è  Temps d'entra√Ænement: {train_time:.2f}s\")\n",
    "\n",
    "# Barre de progression pour la pr√©diction\n",
    "print(\"\\n Pr√©dictions en cours...\")\n",
    "with tqdm(total=100, desc=\"Pr√©diction\", bar_format='{l_bar}{bar}| {percentage:3.0f}%') as pbar:\n",
    "    start_pred = time.time()\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    pred_time = time.time() - start_pred\n",
    "    pbar.update(100)\n",
    "\n",
    "print(f\"‚è±Ô∏è  Temps de pr√©diction: {pred_time:.2f}s\")\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\n R√©sultats:\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\" Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\n Rapport de classification:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "278c0576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARAISON TRAIN/TEST ===\n",
      "BayesianClassifier: 0.7550\n",
      "RandomForest:       0.8300\n"
     ]
    }
   ],
   "source": [
    "# Question 3 : comparaison avec RandomForest + validation crois√©e stratifi√©e\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Pipeline RandomForest avec parall√©lisation\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=n_cores_use))\n",
    "])\n",
    "\n",
    "# Entra√Ænement et test simple d'abord\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"=== COMPARAISON TRAIN/TEST ===\")\n",
    "print(f\"BayesianClassifier: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RandomForest:       {accuracy_score(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c008c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'erreurs: 49\n",
      "\n",
      "Structure apprise - Ar√™tes: [('f_0', 'f_1')]\n",
      "\n",
      "Erreur 1:\n",
      "  Vraie: Y | Pr√©dite: N\n",
      "  Features: {'months_as_customer': 230, 'age': 37, 'policy_number': 776950}\n",
      "  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\n",
      "\n",
      "Erreur 2:\n",
      "  Vraie: Y | Pr√©dite: N\n",
      "  Features: {'months_as_customer': 101, 'age': 33, 'policy_number': 575000}\n",
      "  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\n",
      "\n",
      "Erreur 3:\n",
      "  Vraie: Y | Pr√©dite: N\n",
      "  Features: {'months_as_customer': 266, 'age': 42, 'policy_number': 929306}\n",
      "  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\n",
      "\n",
      "Erreur 4:\n",
      "  Vraie: Y | Pr√©dite: N\n",
      "  Features: {'months_as_customer': 234, 'age': 44, 'policy_number': 442494}\n",
      "  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\n",
      "\n",
      "Erreur 5:\n",
      "  Vraie: Y | Pr√©dite: N\n",
      "  Features: {'months_as_customer': 14, 'age': 28, 'policy_number': 335780}\n",
      "  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\n"
     ]
    }
   ],
   "source": [
    "# Question 4 : analyse des erreurs avec la structure du r√©seau bay√©sien\n",
    "\n",
    "y_pred_final = pipeline.predict(X_test)\n",
    "errors_mask = y_test != y_pred_final\n",
    "print(f\"Total d'erreurs: {errors_mask.sum()}\")\n",
    "\n",
    "# Structure apprise ?\n",
    "clf = pipeline.named_steps['classifier']\n",
    "if hasattr(clf, 'learned_structure_') and clf.learned_structure_:\n",
    "    print(f\"\\nStructure apprise - Ar√™tes: {list(clf.model.edges())}\")\n",
    "\n",
    "# 5 premi√®res erreurs\n",
    "error_indices = y_test[errors_mask].index[:5]\n",
    "for i, idx in enumerate(error_indices):\n",
    "    print(f\"\\nErreur {i+1}:\")\n",
    "    print(f\"  Vraie: {y_test.loc[idx]} | Pr√©dite: {y_pred_final[y_test.index.get_loc(idx)]}\")\n",
    "    print(f\"  Features: {X_test.loc[idx].head(3).to_dict()}\")\n",
    "    if hasattr(clf, 'learned_structure_') and clf.learned_structure_:\n",
    "        print(\"  ‚Üí Structure bay√©sienne utilis√©e pour cette pr√©diction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
